<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo.jpg">
  <link rel="mask-icon" href="/images/logo.jpg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"luyanan.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="分布式消息通信之Kafka 的实现原理消息中间件能做什么?消息中间件主要解决的就是分布式系统之间消息的传递问题, 它能够屏蔽各种平台以及协议之间的特性,实现应用程序之间的协同. 举个简单的例子, 就拿一个电商平台的注册功能来简单分析一下,用户注册这一个服务,不仅仅只是insert 一条数据库里面就完事了, 还需要发送激活邮件、发送新人红包或者积分、发送营销短信等一些列操作. 假如说这里面的每一个操">
<meta property="og:type" content="article">
<meta property="og:title" content="分布式消息通信值Kafka的实现原理">
<meta property="og:url" content="http://luyanan.com/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%80%9A%E4%BF%A1%E5%80%BCKafka%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/index.html">
<meta property="og:site_name" content="程序员报社">
<meta property="og:description" content="分布式消息通信之Kafka 的实现原理消息中间件能做什么?消息中间件主要解决的就是分布式系统之间消息的传递问题, 它能够屏蔽各种平台以及协议之间的特性,实现应用程序之间的协同. 举个简单的例子, 就拿一个电商平台的注册功能来简单分析一下,用户注册这一个服务,不仅仅只是insert 一条数据库里面就完事了, 还需要发送激活邮件、发送新人红包或者积分、发送营销短信等一些列操作. 假如说这里面的每一个操">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://files.luyanan.com//img/20191227142436.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191227143130.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191227143344.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191227165011.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191227165050.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191227200345.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191228091254.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191228113737.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191228162955.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191228164242.png">
<meta property="og:image" content="http://files.luyanan.com//img/20191228173121.png">
<meta property="article:published_time" content="2021-03-02T05:42:51.780Z">
<meta property="article:modified_time" content="2021-03-02T05:42:51.781Z">
<meta property="article:author" content="luyanan">
<meta property="article:tag" content="Python, Rust, C++, Go, 爬虫, 深度学习, 服务研发, 对象存储">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://files.luyanan.com//img/20191227142436.png">

<link rel="canonical" href="http://luyanan.com/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%80%9A%E4%BF%A1%E5%80%BCKafka%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>分布式消息通信值Kafka的实现原理 | 程序员报社</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="程序员报社" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">程序员报社</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">程序员报社</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://luyanan.com/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%80%9A%E4%BF%A1%E5%80%BCKafka%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo.jpg">
      <meta itemprop="name" content="luyanan">
      <meta itemprop="description" content="程序员报社">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="程序员报社">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          分布式消息通信值Kafka的实现原理
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-02 13:42:51" itemprop="dateCreated datePublished" datetime="2021-03-02T13:42:51+08:00">2021-03-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" itemprop="url" rel="index"><span itemprop="name">微服务</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="分布式消息通信之Kafka-的实现原理"><a href="#分布式消息通信之Kafka-的实现原理" class="headerlink" title="分布式消息通信之Kafka 的实现原理"></a>分布式消息通信之Kafka 的实现原理</h1><h2 id="消息中间件能做什么"><a href="#消息中间件能做什么" class="headerlink" title="消息中间件能做什么?"></a>消息中间件能做什么?</h2><p>消息中间件主要解决的就是分布式系统之间消息的传递问题, 它能够屏蔽各种平台以及协议之间的特性,实现应用程序之间的协同. 举个简单的例子, 就拿一个电商平台的注册功能来简单分析一下,用户注册这一个服务,不仅仅只是insert 一条数据库里面就完事了, 还需要发送激活邮件、发送新人红包或者积分、发送营销短信等一些列操作. 假如说这里面的每一个操作都需要消耗1s , 那么整个注册过程就需要耗时4s 才能响应给用户.</p>
<p><img src="http://files.luyanan.com//img/20191227142436.png"></p>
<p>但是我们从注册这个服务可以看到, 每一个子操作都是相对独立的. 同时, 基于领域划分后, 发送激活邮件、发送营销短信、赠送积分以及红包都属于不同的子域. 所以我们可以读这些子操作进行实现异步化执行, 类似于多线程并行处理的概念. </p>
<p>如何实现异步化呢? 用多线程去实现吗? 多线程当然可以实现, 只是, 消息的持久化、消息的重发这些条件, 多线程并不能满足, 所以需要借助一些开源中间件来解决. 而分布式消息队列就是一个非常好的解决方法, 引入分布式消息队列以后, 架构图就变成了这样了(下图是异步消息队列的场景). 通过引入分布式队列， 就能够大大提升程序的处理效率, 并且还解决了各个模块之间的耦合问题. </p>
<blockquote>
<p> 这个是分布式消息队列的第一个解决场景: 异步处理</p>
</blockquote>
<p><img src="http://files.luyanan.com//img/20191227143130.png"></p>
<p>我们再来展开一种场景,通过分布式消息队列来实现流量整形, 比如在电商平台的秒杀场景, 流量会非常大, 通过消息队列的方式就可以很好的缓解高流量的问题. </p>
<p><img src="http://files.luyanan.com//img/20191227143344.png"></p>
<ul>
<li>用户提交过来的请求, 先写入到消息队列. 消息队列是有长度的, 如果消息队列超过指定的长度, 则直接抛弃. </li>
<li>秒杀的具体核心处理业务, 接受消息队列中消息进行处理, 这里的消息处理能力取决于消费端本身的吞吐量. </li>
</ul>
<p>当然, 消息中间件还有更多的应用场景, 比如在弱一致性事务模型中, 可以采用分布式消息队列的实现最大能力通知方式来实现数据的最终一致性问题等等. </p>
<h2 id="Java-中使用Kafka-进行通信"><a href="#Java-中使用Kafka-进行通信" class="headerlink" title="Java 中使用Kafka 进行通信."></a>Java 中使用Kafka 进行通信.</h2><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span> </span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="发送端代码"><a href="#发送端代码" class="headerlink" title="发送端代码"></a>发送端代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mq.kafka.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.IntegerSerializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> luyanan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2019/12/27</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;发送端&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaProducer&lt;Integer, String&gt; producer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String topic)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.86.128:9092&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.CLIENT_ID_CONFIG, <span class="string">&quot;producer&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        producer = <span class="keyword">new</span> KafkaProducer&lt;Integer, String&gt;(properties);</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (num &lt; <span class="number">50</span>) &#123;</span><br><span class="line">                String msg = <span class="string">&quot;test  msg : &quot;</span> + num;</span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;Integer, String&gt;(topic, msg)).get();</span><br><span class="line">                TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">                System.out.println(<span class="string">&quot;发送消息&quot;</span> + msg);</span><br><span class="line">                num++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Producer(<span class="string">&quot;test&quot;</span>).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="消费端代码"><a href="#消费端代码" class="headerlink" title="消费端代码"></a>消费端代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mq.kafka.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.IntegerDeserializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> luyanan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2019/12/27</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;消费端&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaConsumer&lt;Integer, String&gt; consumer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Consumer</span><span class="params">(String topic)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.86.128:9092&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">true</span>);<span class="comment">//  设置offset 自动提交</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br><span class="line">        properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, <span class="number">30000</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">&quot;earliest&quot;</span>); <span class="comment">// 当前groupid来说，消息的offset从最早的消息开始消费</span></span><br><span class="line">        consumer = <span class="keyword">new</span> KafkaConsumer&lt;Integer, String&gt;(properties);</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            consumer.subscribe(Collections.singleton(<span class="keyword">this</span>.topic));</span><br><span class="line">            ConsumerRecords&lt;Integer, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            records.forEach(record -&gt; &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;key:&quot;</span> + record.key() + <span class="string">&quot;--value: &quot;</span> + record.value() + <span class="string">&quot;--offset: &quot;</span> + record.offset());</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Consumer(<span class="string">&quot;test&quot;</span>).start();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="异步发送"><a href="#异步发送" class="headerlink" title="异步发送"></a>异步发送</h3><p>Kafka 对于消息的发送，可以支持同步和异步, 前面演示的案例中,我们是基于同步发送消息, 同步会需要阻塞, 而异步不需要等待阻塞的过程. </p>
<p>从本质上来说, Kafka 都是采用异步的方式来发送消息到broker, 但是kafka 并不是每次都发送消息都会直接发送到broker, 而是把消息放到了一个发送队列中, 然后通过一个后台线程不断从队列取出消息进行发送,发送成功后悔触发<code>callback</code>。 Kafka 客户端会积累一定量的消息统一组装成一个批量消息发送出去, 触发条件是前面提到的 <code>batch.size</code>和 <code>linger.ms</code>. </p>
<p>而同步发送的方法, 无非就是通过 <code>future.get()</code> 来等待消息的发送返回结果, 但是这种方法会严重影响消息发送的性能. </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (num &lt; <span class="number">50</span>) &#123;</span><br><span class="line">            String msg = <span class="string">&quot;test  msg : &quot;</span> + num;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, msg), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">                    System.out.println(<span class="string">&quot;callback-&gt; offset: &quot;</span> + recordMetadata.offset() + <span class="string">&quot;--partition: &quot;</span> + recordMetadata.partition());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">            num++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="batch-size"><a href="#batch-size" class="headerlink" title="batch.size"></a>batch.size</h3><p>生产者发送多个消息到broker 的同一个分区的时候, 为了减少网络请求带来的性能开销, 通过批量的方式来提交信息, 可以通过这个参数来控制批量提交的字节数大小, 默认大小是 16384byte, 也就是16kb, 意味着当一批消息大小达到指定的<code>batch.size</code> 的时候会统一发送. </p>
<h3 id="linger-ms"><a href="#linger-ms" class="headerlink" title="linger.ms"></a>linger.ms</h3><p>Producer 默认会把两次发送时间间隔内收到的所有Requests  进行一次聚合然后进行发送, 以此提高吞吐量, 而<code>linger.ms</code>  及时为每次发送到broker 的请求增加一些delay, 以此来聚合更多的Message 请求. 这个有点像TCP里面的Nagle算法, 在TCP 协议的传输中, 为了减少大量小数据包的发送,采用了Nagle 算法, 也就是基于小包的等-停协议. </p>
<blockquote>
<p>batch.size和linger.ms 这两个参数是Kafka 性能优化的关键参数, 当二者都配置的时候, 只要满足其中一个要求, 都会发送请求到Broker. </p>
</blockquote>
<h2 id="一些基础配置分析"><a href="#一些基础配置分析" class="headerlink" title="一些基础配置分析"></a>一些基础配置分析</h2><h3 id="group-id"><a href="#group-id" class="headerlink" title="group.id"></a>group.id</h3><p>consumer group 是Kafka 提供的可扩展且具有容错性的消费机制. 既然是一个组, 那么组内必然可以有多个消费者或者消费者实例, 他们共享一个公共 的ID， 即Group ID. 组内的所有消费者协调在一起来消费订阅主题(subscribed topics) 的所有分区(partition).  当然, 每个分区只能由一个消费者组内的一个 consumer 来消费。 如下图所示： 分别有三个消费者, 属于两个不同的group, 那么对于<code>firstTopic</code> 这个topic 来说, 这两个组的消费者都能同时消费这个topic 的消息, 对于此时的架构来说, 这个<code>firstTopic</code> 就类似于ActiveMQ 中的topic 概念. 如下图所示, 如果这三个消费者都属于同一个group, 那么此时<code>firstTopic</code> 就是一个Queue 的概念。 </p>
<p><img src="http://files.luyanan.com//img/20191227165011.png"></p>
<p><img src="http://files.luyanan.com//img/20191227165050.png"></p>
<h3 id="enable-auto-commit"><a href="#enable-auto-commit" class="headerlink" title="enable.auto.commit"></a>enable.auto.commit</h3><p>消费者消费消息之后自动提交, 只有当消息提交后, 该消息才不会被再次接收到， 还可以配合<code>auto.commit.interval.ms</code> 控制自动提交的频率. </p>
<p>当然, 我们也可以通过<code>consumer.commitSync()</code> 的方式实现手动提交. </p>
<h3 id="auto-offset-reset"><a href="#auto-offset-reset" class="headerlink" title="auto.offset.reset"></a>auto.offset.reset</h3><p>这个参数是针对新的group Id 中的消费者而言, 当有新的groupId 的消费者来消费指定的topic 时, 对于该参数的配置, 会有不同的语义. </p>
<p><code>auto.offset.reset=latest</code>的情况下, 新的消费者将会从其他消费者最后消费的 offset 处开始消费Topic 下的消息</p>
<p><code>auto.offset.reset= earliest</code> 的情况下, 新的消费者会从该topic 最早的消息进行消费. </p>
<p><code>auto.offset.reset=none</code>的情况下, 新的消费者加入后, 如果之前不存在offset,则会直接抛出异常. </p>
<h3 id="max-poll-records"><a href="#max-poll-records" class="headerlink" title="max.poll.records"></a>max.poll.records</h3><p>此设置限制每次调用poll返回的消息数，这样可以更容易的预测每次poll 间隔要处理的最大值，通过调整此值, 可以减少poll 间隔. </p>
<h2 id="Spring-整合Kafka"><a href="#Spring-整合Kafka" class="headerlink" title="Spring 整合Kafka"></a>Spring 整合Kafka</h2><p>SpringBoot 的版本和Kafka的版本有一个对照表格，如果没有按照正确的版本引入, 那么会存在版本问题导致  <code>ClassNotFound</code> 的问题, 具体请参考</p>
<blockquote>
<p> <a target="_blank" rel="noopener" href="https://spring.io/projects/spring-kafka">https://spring.io/projects/spring-kafka</a></p>
</blockquote>
<h3 id="Jar-依赖"><a href="#Jar-依赖" class="headerlink" title="Jar 依赖"></a>Jar 依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> luyanan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2019/12/27</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;生产者&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(String msg)</span> </span>&#123;</span><br><span class="line">        kafkaTemplate.send(<span class="string">&quot;spring-test&quot;</span>, <span class="string">&quot;key&quot;</span>, <span class="string">&quot;msgData:&quot;</span> + msg);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.annotation.KafkaListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Optional;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> luyanan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2019/12/27</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;消费者&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &#123;&quot;spring-test&quot;&#125;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listener</span><span class="params">(ConsumerRecord record)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Optional&lt;Object&gt; optional = Optional.ofNullable(record.value());</span><br><span class="line">        <span class="keyword">if</span> (optional.isPresent()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;接受到的消息为: &quot;</span> + optional.get());</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">spring.kafka.bootstrap-servers</span>=<span class="string">192.168.86.128:9092</span></span><br><span class="line"><span class="meta">spring.kafka.producer.key-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="meta">spring.kafka.producer.value-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.group-id</span>=<span class="string">spring-test-group</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.auto-offset-reset</span>=<span class="string">earliest</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.enable-auto-commit</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.key-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.value-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="meta">spring.kafka.listener.missing-topics-fatal</span>=<span class="string">false</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.ConfigurableApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringKafkaApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ConfigurableApplicationContext applicationContext = SpringApplication.run(SpringKafkaApplication.class, args);</span><br><span class="line">        KafkaProducer producer = applicationContext.getBean(KafkaProducer.class);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">30</span>; i++) &#123;</span><br><span class="line">            producer.send(i + <span class="string">&quot;&quot;</span>);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2><p>从前面的整个演示过程来看, 只要不是超大规模的使用Kafka, 那么基本上就没什么大问题, 否则, 对于Kafka 本身的运维本身的挑战难度很多, 同时,针对每一个参数的调优也显得很重要. </p>
<h3 id="关于Topic和Partition"><a href="#关于Topic和Partition" class="headerlink" title="关于Topic和Partition"></a>关于Topic和Partition</h3><h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>在Kafka中, Topic 是一个存储消息的逻辑概念, 可以认为是一个消息集合, 每条消息发送到Kafka 集群的消息都有一个类别。物理上说, 不同的topic 是分开存储的. </p>
<p>每个topic 可以有多个生产者向它发送消息, 也可以有多个消费者去消费其中的消息. </p>
<p><img src="http://files.luyanan.com//img/20191227200345.png"></p>
<h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><p>每个topic 可以划分为多个分区(每个Topic 至少有一个分区), 同一个topic 下的不同分区包含的消息是不同的, 每个消息在被添加到分区时, 都会被分配一个 offset(称之为偏移量), 它是消息在此分区中的唯一编号, kafka通过offset 保证消息在分区内的顺序, offset的顺序不跨分区, 即Kafka 只能保证在同一个分区内的消息是有序的 </p>
<p>下图中, 对于名字为<code>test</code>的 topic ,做了三个分区, 分别是p0,p1,p2</p>
<blockquote>
<p>每条消息发送到broker的时候, 会根据partition 的规则选择存储到哪一个partition. 如果partition 规则设置合理, 那么所有的消息都会均匀的分布在不同的partition中, 这样就类似数据库的分库分表的概念,把数据做了分片处理.</p>
</blockquote>
<p><img src="http://files.luyanan.com//img/20191228091254.png"></p>
<h4 id="Topic和Partition-的存储"><a href="#Topic和Partition-的存储" class="headerlink" title="Topic和Partition 的存储"></a>Topic和Partition 的存储</h4><p>Partition 是以文件的形式存储在文件系统中,必须创建一个名为<code>firstTopic</code>的topic,其中有三个partition, 那么在kafka 的数据目录(/tmp/kafka-logs) 中就有三个目录, firstTopic-0-3,  命名规则是 <code>&lt;topic_name&gt;-&lt;partition_id&gt;</code></p>
<blockquote>
<p>sh kafka-topics.sh –create –zookeeper 192.168.11.156:2181–replication-factor 1 –partitions 3 –topic firstTopic</p>
</blockquote>
<h2 id="关于消息分发"><a href="#关于消息分发" class="headerlink" title="关于消息分发"></a>关于消息分发</h2><h3 id="Kafka-消息分发策略"><a href="#Kafka-消息分发策略" class="headerlink" title="Kafka 消息分发策略"></a>Kafka 消息分发策略</h3><p>消息是kafka 中最基本的数据单位, 在kafka中, 一条消息是由 key、value 两部分构成, 在发送一条消息时,我们可以指定这个key, 那么producer 会根据key和partition 机制来判断当前这条消息应该发送并且存储到哪个partition,  我们可以根据需要进行扩展producer 的partition. </p>
<h3 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h3><h4 id="自定义partition"><a href="#自定义partition" class="headerlink" title="自定义partition"></a>自定义partition</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mq.kafka.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.PartitionInfo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> luyanan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2019/12/28</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;自定义Partition&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String s, Object o, <span class="keyword">byte</span>[] bytes, Object o1, <span class="keyword">byte</span>[] bytes1, Cluster cluster)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//  获取集群中指定topic 的所有分区信息</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitionInfos = cluster.partitionsForTopic(s);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> size = partitionInfos.size();</span><br><span class="line">        <span class="keyword">int</span> partitionNum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">            partitionNum = random.nextInt(size);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            partitionNum = Math.abs(o1.hashCode()) % size;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;key-&gt;&quot;</span> + o + <span class="string">&quot;:value-&gt;&quot;</span> + o1 + <span class="string">&quot;:send to partition-&gt;&quot;</span> + partitionNum);</span><br><span class="line">        <span class="keyword">return</span> partitionNum;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="发送端代码添加到自定义分区"><a href="#发送端代码添加到自定义分区" class="headerlink" title="发送端代码添加到自定义分区"></a>发送端代码添加到自定义分区</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mq.kafka.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.IntegerSerializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> luyanan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2019/12/28</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;自定义Partition&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isAysnc;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaProducer&lt;Integer, String&gt; producer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">KafkaProducerDemo</span><span class="params">(String topic, <span class="keyword">boolean</span> isAysnc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">        <span class="keyword">this</span>.isAysnc = isAysnc;</span><br><span class="line"></span><br><span class="line">        Properties config = <span class="keyword">new</span> Properties();</span><br><span class="line">        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.86.128:9092&quot;</span>);</span><br><span class="line">        config.put(ProducerConfig.CLIENT_ID_CONFIG, <span class="string">&quot;kafkaProduceDemo&quot;</span>);</span><br><span class="line">        config.put(ProducerConfig.ACKS_CONFIG, -<span class="number">1</span>);</span><br><span class="line">        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName());</span><br><span class="line">        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        config.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class.getName());</span><br><span class="line">        producer = <span class="keyword">new</span> KafkaProducer&lt;Integer, String&gt;(config);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="消息的默认分发机制"><a href="#消息的默认分发机制" class="headerlink" title="消息的默认分发机制"></a>消息的默认分发机制</h3><p>默认情况下, kafka 采用的是hash 取模的分区算法, 如果key为null, 则会随机分配一个分区, 这个随机是在这个参数 <code>metadata.max.age.ms</code> 的时间范围内随机选择一个. 对于这个时间段内, 如果key 为null, 则只会发送到唯一的分区, 这个值默认的情况下是10分钟更新一次. </p>
<p>关于<code>Metadata</code>, 简单理解就是Topic/Partition和Broker 的映射关系, 每一个topic 的每一个partition , 需要知道对应的broker 列表是什么?  leader 是谁？ follower 是谁. 这些信息都是存储在<code>Metadata</code> 这个类中. </p>
<h3 id="消费端如何消费指定的分区"><a href="#消费端如何消费指定的分区" class="headerlink" title="消费端如何消费指定的分区"></a>消费端如何消费指定的分区</h3><p>通过下面的代码, 就可以消费指定该topic 下的0号分区, 其他分区的数据就无法接受</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TopicPartition topicPartition = <span class="keyword">new</span> TopicPartition(<span class="keyword">this</span>.topic, <span class="number">0</span>);</span><br><span class="line">consumer.assign(Arrays.asList(topicPartition));</span><br></pre></td></tr></table></figure>



<h2 id="消息的消费原理"><a href="#消息的消费原理" class="headerlink" title="消息的消费原理"></a>消息的消费原理</h2><h3 id="Kafka消息消费原理演示"><a href="#Kafka消息消费原理演示" class="headerlink" title="Kafka消息消费原理演示"></a>Kafka消息消费原理演示</h3><p>在实际生产过程中, 每个topic 都会有多个partition, 多个partition 的好处在于, 一方面能够对broker 上的数据进行分片有效减少了消息的容错从而提升了io性能. 另一方面, 为了提高消费端的消费能力, 一般会通过多个consumer 去消费同一个topic, 也就是消费端的负载均衡机制, 也就是我们接下来要了解的, 在多个partition以及多个consumer 的情况下,消费者是如何消费消息的. </p>
<p>同时，我们知道kafka 存在consumer group 的概念, 也就是group.id 一样的consumer 属于一个<code>consumer group</code>, 组内的所有消费者协调在一起来消费订阅主题的所有分区. 当然每一个分区只能由同一个消费组内的consumer 来消费, 那么在同一个consumer group 里面的consumer 是怎么去分配该消费哪个分区里的数据呢? 如下图所示:3个分区、3个消费者, 那么哪个消费者消费哪个分区? </p>
<p><img src="http://files.luyanan.com//img/20191228113737.png"></p>
<p>对于上面这个图来说, 这3个消费者会分别消费test 这个 topic 的3个分区, 也就是每个consumer 消费一个partition. </p>
<h4 id="代码演示-3个partition-对应3个consumer"><a href="#代码演示-3个partition-对应3个consumer" class="headerlink" title="代码演示(3个partition 对应3个consumer)"></a>代码演示(3个partition 对应3个consumer)</h4><ul>
<li>创建一个带3个分区的topic</li>
<li>启动3个消费者消费同一个topic, 并且这3个consumer 属于同一个组</li>
<li>启动发送者进行消费发送</li>
</ul>
<blockquote>
<p> 演示结果：consumer1会消费partition0分区、consumer2会消费partition1分区、consumer3会消费 partition2分区 如果是2个consumer消费3个partition呢？会是怎么样的结果？</p>
</blockquote>
<h4 id="代码演示-3个partition-对应2个consumer"><a href="#代码演示-3个partition-对应2个consumer" class="headerlink" title="代码演示(3个partition 对应2个consumer)"></a>代码演示(3个partition 对应2个consumer)</h4><ul>
<li>基于上面演示的案例的topic 不变</li>
<li>启动2个消费者消费该topic</li>
<li>启动发送者进行发送消息</li>
</ul>
<blockquote>
<p>演示结果: consumer1会消费partition0和partition1分区, consumer2 会消费partition2分区. </p>
</blockquote>
<h4 id="代码演示-3个partition-对应4个或者4个以上的consumer"><a href="#代码演示-3个partition-对应4个或者4个以上的consumer" class="headerlink" title="代码演示(3个partition  对应4个或者4个以上的consumer)"></a>代码演示(3个partition  对应4个或者4个以上的consumer)</h4><blockquote>
<p>演示结果: 仍然只有3个consumer 对应3个partition, 其他的consumer 无法消费消息. </p>
<p>通过这个演示的过程，希望引入接下来需要了解的kafka的分区策略(<code>Partition Assignment Strategy</code>)</p>
</blockquote>
<h3 id="consumer和partition的数量建议"><a href="#consumer和partition的数量建议" class="headerlink" title="consumer和partition的数量建议"></a>consumer和partition的数量建议</h3><ul>
<li>如果consumer 比partition多,是浪费, 因为kafka 的设计时是在一个partition 上是不允许转发的, 所以consumer 数不要大于partition数</li>
<li>如果consumer数比partition少, 一个consumer 会对应几个partition, 这里主要合理分配consumer数和partition数,否则会导致partition 里面的数据被取的不均匀. 最好partition 数目是consumer 数目的整数倍, 所以partition 的数目很重要, 比如取24, 就很容易设定consumer 的数目. </li>
<li>如果consumer 上多个partition 读取数据, 不保证数据间的顺序性, kafka 只保证在一个partition 上数据是有序的,但是多个partition, 根据你读的顺序会有所不同. </li>
<li>增减consumer ,broker\partition 会导致 <code>rebalance</code>, 所以<code>rebalance</code> 后consumer 对应的 partition 会发生变化. </li>
</ul>
<h3 id="思考-什么时候会触发这个策略呢"><a href="#思考-什么时候会触发这个策略呢" class="headerlink" title="思考: 什么时候会触发这个策略呢?"></a>思考: 什么时候会触发这个策略呢?</h3><p>当出现这几种情况时, kafka 会进行一次分区分配操作, 也就是 kafka consumer 的 rebalance</p>
<ol>
<li>同一个consumer group 内新增了消费者</li>
<li>消费者离开当前所属的consumer  group,比如主动停机或者宕机</li>
<li>topic 新增加了分区(也就是分区数量发生了变化)</li>
</ol>
<p>kafka consumer 的rebalance 机制规定了一个 consumer group 下的 所有consumer 如何达成一致来分配订阅topic 的每个分区, 而具体如何执行分区策略,就是前面提到过的两种内置的分区策略. 而kafka 对于分配策略这块, 提供了可拔插的实现方式, 也就是说, 除了这两种之外, 我们还可以创建自己的分区机制. </p>
<h3 id="什么是分区分配策略"><a href="#什么是分区分配策略" class="headerlink" title="什么是分区分配策略"></a>什么是分区分配策略</h3><p>通过前面的案例演示, 我们应该能猜到, 同一个group 中的消费者对于一个topic 中的多个partition, 存在一定的分区分配策略. </p>
<p>在kafka 中, 存在三种分区分配策略, 一种是Range(默认), 另一种是RoundRobin(轮询), StickyAssignor(粘性). 在消费端中的<code>consumerConfig</code> 中, 通过这个属性来指定分区分配策略.</p>
<blockquote>
<p> public static final String PARTITION_ASSIGNMENT_STRATEGY_CONFIG = “partition.assignment.strategy”;</p>
</blockquote>
<h4 id="RangeAssignor（范围分区）"><a href="#RangeAssignor（范围分区）" class="headerlink" title="RangeAssignor（范围分区）"></a>RangeAssignor（范围分区）</h4><p>Range 策略是对每个主题而言的, 首先对同一个主题里面的分区按照序号进行排序, 并对消费者按照字母顺序进行排序. </p>
<blockquote>
<p> 假设n = 分区数/消费者数量</p>
<p>m= 分区数%消费者数量</p>
<p>那么前m个消费者每个分配n+1个分区, 后面的(消费者数量-m) 个消费者每个分配n个分区. </p>
</blockquote>
<p>假设我们有10个分区, 3个消费者, 排完序的分区会是0,1,2,3,4,5,6,7,8,9; 消费者线程排完序将会是C1-0,C2-0,C3-0； 然后将partition的个数除以消费者线程的总数来决定每个消费者线程消费几个分区. 如果除不尽, 那么前面几个消费者将会多消费一个分区. 在我们的例子中,我们有10个分区， 3个消费者, 10/3 =3 而且除不尽,那么消费者线程C1-0 就会多消费一个分区. </p>
<p>**结果看起来是这样的: **</p>
<ul>
<li>C1-0 将消费0,1,2,3 分区</li>
<li>C2-0 将消费4,5,6 分区</li>
<li>C3-0 将消费7,8,9 分区</li>
</ul>
<p><strong>假设我们有11个分区, 那么最后分区分配的结果看起来是这样的:</strong></p>
<ul>
<li>C1-0 将消费0,1,2,3 分区</li>
<li>C2-0 将消费4,5,6 分区</li>
<li>C3-0 将消费7,8,9 分区</li>
</ul>
<p><strong>假设我们有2个主题(T1,T2), 分别有10个分区, 那么最后分区分配的结果是这样的</strong>: </p>
<ul>
<li><p>C1-0 将消费T1主题的0,1,2,3 分区以及T2主题的0,1,2,3分区</p>
</li>
<li><p>C2-0 将消费T1主题的4,5,6,分区和T2主题的4,5,6分区</p>
</li>
<li><p>C3-0将消费T1主题的7,8,9分区和T2主题的7,8,9分区</p>
<blockquote>
<p>可以看出, C1-0 消费者线程比其他消费者线程多消费了2个分区, 这就是<code>Range strategy</code>的一个很明显的弊端. </p>
</blockquote>
</li>
</ul>
<h4 id="RoundRobinAssignor（轮询分区）"><a href="#RoundRobinAssignor（轮询分区）" class="headerlink" title="RoundRobinAssignor（轮询分区）"></a>RoundRobinAssignor（轮询分区）</h4><p>轮询分区策略是把所有的protition 和所有的consumer 线程都列出来, 然后按照hashcode 进行排序. 最后通过轮询算法分配partition 给消费者线程. 如果所有的consumer 实例的订阅是相同的, 那么partition 会均匀分布. </p>
<p>在我们的例子里面, 假如按照hashcode 排序完的top-partition 组依次为T1-5, T1-3, T1-0, T1-8, T1- 2, T1-1, T1-4, T1-7, T1-6, T1-9，我们的消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果 为：</p>
<ul>
<li>C1-0 将消费 T1-5, T1-2, T1-6 分区； </li>
<li>C1-1 将消费 T1-3, T1-1, T1-9 分区；</li>
<li>C2-0 将消费 T1-0, T1-4 分区； </li>
<li>C2-1 将消费 T1-8, T1-7 分区；</li>
</ul>
<p>使用轮询分区策略必须满足两个条件: </p>
<ol>
<li>每个主题的消费者实例具有相同数量的流</li>
<li>每个消费者订阅的主题必须是相同的. </li>
</ol>
<h4 id="StrickyAssignor-分配策略"><a href="#StrickyAssignor-分配策略" class="headerlink" title="StrickyAssignor 分配策略"></a>StrickyAssignor 分配策略</h4><p>kafka 在0.11X 版本中支持了 <code>StrickyAssignor</code>,翻译过来叫 粘滞策略,他主要有两个目的:</p>
<ul>
<li>分区的分配尽可能的均匀</li>
<li>分区的分配尽可能的和上次分配保持相同. </li>
</ul>
<p>当两者发生冲突的时候, 第一个目标优先于第二个目标. 鉴于这两个目标, StrickyAssignor 分配策略的具体实现要比RangeAssignor和RoundRobinAssi gn or 这两种分配策略要复杂的多, 假设我们有这样一个场景: </p>
<blockquote>
<p>假设消费组有3个消费者：C0,C1,C2，它们分别订阅了4个Topic(t0,t1,t2,t3),并且每个主题有两个分 区(p0,p1),也就是说，整个消费组订阅了8个分区：tOpO 、 tOpl 、 tlpO 、 tlpl 、 t2p0 、 t2pl 、t3p0 、 t3pl </p>
<p>那么最终的分配场景结果为 </p>
<p>CO: tOpO、tlpl 、 t3p0 </p>
<p>Cl: tOpl、t2p0 、 t3pl </p>
<p>C2: tlpO、t2pl </p>
<p>这种分配方式有点类似于轮询策略，但实际上并不是，因为假设这个时候，C1这个消费者挂了，就势必会造成 重新分区（reblance），如果是轮询，那么结果应该是</p>
<p> CO: tOpO、tlpO、t2p0、t3p0 </p>
<p>C2: tOpl、tlpl、t2pl、t3pl</p>
<p> 然后，strickyAssignor它是一种粘滞策略，所以它会满足<code>分区的分配尽可能和上次分配保持相同</code>，所以 分配结果应该是 </p>
<p>消费者CO: tOpO、tlpl 、 t3p0、t2p0 </p>
<p>消费者C2: tlpO、t2pl、tOpl、t3pl </p>
<p>也就是说，C0和C2保留了上一次是的分配结果，并且把原来C1的分区分配给了C0和C2。 这种策略的好处是 使得分区发生变化时，由于分区的“粘性，减少了不必要的分区移动</p>
</blockquote>
<h3 id="谁来执行-rebalance-以及管理consumer-的group-呢"><a href="#谁来执行-rebalance-以及管理consumer-的group-呢" class="headerlink" title="谁来执行 rebalance 以及管理consumer 的group 呢?"></a>谁来执行 rebalance 以及管理consumer 的group 呢?</h3><p>kafka 提供了一个角色: <code>coordinator</code> 来执行对consumer group 的管理. 当 consumer group 的第一个consumer 启动的时候, 它会去和kafka server 确定谁是他们组的<code>coordinator</code>.之后该group 内的所有成员都和该<code>coordinator</code> 进行协调通信. </p>
<h3 id="如何确定coordinator"><a href="#如何确定coordinator" class="headerlink" title="如何确定coordinator"></a>如何确定coordinator</h3><p>consumer group 如何确定自己的<code>coordinator</code> 是谁呢? 消费者向kafka 集群中的任意一个broker 发送一个GroupCoordinatorRequest 请求, 服务端会返回一个负载最小的broker 节点的id, 并将该broker 设置为coordinator</p>
<h3 id="JoinGroup-的过程"><a href="#JoinGroup-的过程" class="headerlink" title="JoinGroup 的过程"></a>JoinGroup 的过程</h3><p>在rebalance 之前, 需要保证coordinator 是已经确定好的, 整个 rebalance 的过程分为两个步骤:  Join和Sync</p>
<h4 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h4><p>表示加入到consumer group 中, 在这一步, 所有的成员都会向 coordinator 发送 joinGroup的请求. 一旦所有成员都发送了joinGroup 请求, 那么coordinator 会选择一个 consumer 担任leader角色, 并把组成员信息和订阅信息发送到消费者. </p>
<p>leader 选举算法比较简单, 如果消费组内没有leader, 那么第一个加入消费组的消费者就是消费者的leader,如果这个时候leader 消费者推出了消费组, 那么重新选举一个leader, 这个选举很随意, 类似与随机算法. </p>
<p><img src="http://files.luyanan.com//img/20191228162955.png"></p>
<ul>
<li>protocol_metadata: 序列化后的消费者的订阅消息</li>
<li>leader_id: 消费组中的消费者, coordinator  会选择一个作为leader, 对应的就是member_id</li>
<li>member_metadata : 对应消费者的订阅信息</li>
<li>members: consumer group 中全部的消费者的订阅信息</li>
<li>generation_id: 年代信息, 类似于zookeeper 的epoch 是一样的, 对于每一轮rebalance, generation_id 都会递增. 主要用来保护consumer group. 隔离无效的offset, 也就是上一轮的consumer 成员无法提交offset 到新的 consumer group. </li>
</ul>
<p>每个消费者都可以设置自己的分区分配策略, 对于消费组而言, 会从各个消费者上报过来的分区分配策略中选举一个彼此都赞同的策略来实现整体的分区分配, 这个”赞同” 的策略是: 消费组内的各个消费者会通过投票来决定. </p>
<ul>
<li>在joingroup 阶段, 每个consumer 都会把自己支持的分区分配策略发送到coordinator </li>
<li>coordinator  收集到所有消费者的分配策略, 组成一个候选集. </li>
<li>每个消费者需要从候选集中找出一个自己支持的策略,并且为这个策略投票. </li>
<li>最终计算候选集中各个策略的选票数, 票数最多的就是当前消费组的分配策略. </li>
</ul>
<h3 id="Synchronizing-Group-State阶段"><a href="#Synchronizing-Group-State阶段" class="headerlink" title="Synchronizing Group State阶段"></a>Synchronizing Group State阶段</h3><p>完成分区分配之后, 就进入了Synchronizing Group State阶段, 主要逻辑是向GroupCoordinator 发送SyncGroupRequest 请求, 并且处理 SyncGroupResponse 响应. 简单来说, 就是leader 将消费者对应的partition 分配方案同步给 consumer group 中的所有 consumer. </p>
<p><img src="http://files.luyanan.com//img/20191228164242.png"></p>
<p>每个消费者都回向coordinator   发送syncgroup 请求, 不过只有leader 节点会发送分配方案, 其他消费者只是打打酱油而已. 当leader 把方案发给 coordinator    之后, coordinator    会把结果设置到SyncGroupResponse 中, 这样所有的成员都知道自己应该消费哪个分区. </p>
<blockquote>
<p>consumer group 的分区分配方案是在客户端执行的, kafka 将这个权利下发给客户端主要是因为这样有很好的灵活性. </p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>我们再来总结一下consumer group rebalance 的过程</p>
<ol>
<li>对于每个consumer group 子集, 都会在服务端对应一个GroupCoordinator 进行管理. GroupCoordinator 会在zookeeper 上添加watcher, 当消费者加入或者退出consumer  group的时候, 会修改zookeeper 上修改的数据, 从而触发 GroupCoordinato 开始Rebalance 操作. </li>
<li>当消费者准备加入某个 consumer group 或者GroupCoordinator发生故障的时候, 消费者并不知道 GroupCoordinator 在网络中的位置, 这个时候就需要确定 GroupCoordinator, 消费者会向集群中的任意一个broker 节点发送ConsumerMetadataRequest 请求,收到请求的broker 会返回一个response 作为响应. 其中包含管理当前ConsumerGroup的GroupCoordinator.</li>
<li>消费者会根据broker 的返回信息, 连接到GroupCoordinator , 并且发送HeartbeatRequest. 发送心跳的目的是为了保证 GroupCoordinator  这个消费者是正常在线的. 当消费者在指定的时间内没有发送心跳请求，则 GroupCoordinator  会出发 rebalance 操作. </li>
<li><strong>发起join group 请求的两种情况</strong><ol>
<li>如果GroupCoordinator  返回的心跳包数据包含异常,说明GroupCoordinator  因为前面说的集中情况导致了rebalance 操作, 那这个时候，consumer 会发起 join group操作. </li>
<li>新加入的consumer group 的consumer 确定好了GroupCoordinator  之后. 消费者会向GroupCoordinator  发起join group 请求, GroupCoordinator  会收集全部消费者信息之后, 来确认可用的消费者, 并从中选取一个消费者成为group leader. 并把相应的信息(分区分配策略、leader_id…) 封装成一个response返回给所有的消费者. 但是只有group leader 会受到当前consumer group 中的所有消费者信息, 当消费者确定自己是 group leader后, 会根据消费者信息以及选定分区分配策略进行分区分配. </li>
<li>接着进入Synchronizing Group State 阶段, 每个消费者会发送SyncGroupRequest 请求到GroupCoordinator  , 但是只有group leader 的请求会存在分区分配结果, GroupCoordinator   会根据group leader 的分区分配结果形成 SyncGroupResponse 返回给所有的consumer</li>
<li>consumer 根据分配结果, 执行相应的操作. </li>
</ol>
</li>
</ol>
<p>到这里来说, 我们已经知道了消息的发送分区策略, 以及消费者的分区消费策略和rebalance. 对于应用层面来说, 还有一个最重要的东西还没有讲解, 就是offset, 它类似于一个游标, 表示当前消费的消息的位置. </p>
<h3 id="如何保存消费端的消费位置"><a href="#如何保存消费端的消费位置" class="headerlink" title="如何保存消费端的消费位置"></a>如何保存消费端的消费位置</h3><h4 id="什么是offset"><a href="#什么是offset" class="headerlink" title="什么是offset"></a>什么是offset</h4><p>前面在讲解partition的时候, 提到过offset, 每个topic 可以划分多个分区(每个topic 至少有一个分区). 同一个topic 下的不同分区包含的消息是不同的.每个消息在被添加到分区的时候, 都会被分配一个offset(称之为偏移量), 它是消息在此分区中的唯一编号， kafka通过offset保证消息在分区内的顺序, offset 的顺序不跨分区, 即kafka 只保证在同一个分区的消息是有序的. 对于应用层的消费来说,每次消费一个消息并且提交后, 会保存当前消费到的最近的一个offset, 那么offset 保存到哪里呢? </p>
<p><img src="http://files.luyanan.com//img/20191228173121.png"></p>
<h4 id="offset-在哪里维护"><a href="#offset-在哪里维护" class="headerlink" title="offset 在哪里维护"></a>offset 在哪里维护</h4><p>在kafka 中,提供了一个*<em>consumer_offsets_</em> 的一个topic，把offset信息写入到这个topic中*<em>, consumer_offset_</em> 保存了每个consumer group 某个时刻提交的offset 信息. </p>
<p>根据前面我们演示的案例, 我们设置了一个<code>KafkaConsumerDemo</code>的group id . 首先我们需要找到这个 consumer_group 保存在哪个分区. </p>
<blockquote>
<p>properties.put(ConsumerConfig.GROUP_ID_CONFIG,”KafkaConsumerDemo”);</p>
</blockquote>
<p>计算公式: </p>
<blockquote>
<ol>
<li><p>Math.abs(“groupid”.hashCode())%groupMetadataTopicPartitionCount ; 由于默认情况下 groupMetadataTopicPartitionCount有50个分区，计算得到的结果为:35, 意味着当前的 consumer_group的位移信息保存在__consumer_offsets的第35个分区</p>
</li>
<li><p>执行如下命令, 可以查看当前consumer_group中的offset 位移提交的信息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --topic __consumer_offsets --partition 15 --</span><br><span class="line">bootstrap-server 192.168.86.128:9092</span><br><span class="line">--formatter</span><br><span class="line"><span class="string">&#x27;kafka.coordinator.group.GroupMetadataManager$OffsetsMessageFormatter&#x27;</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>从输出结果中,我们就可以知道这个topic 的offset的位移日志. </p>
</li>
</ol>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E4%B9%8BApache%20Dubbo%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%AE%A4%E8%AF%86/" rel="prev" title="微服务治理之Apache Dubbo 的基本认识">
      <i class="fa fa-chevron-left"></i> 微服务治理之Apache Dubbo 的基本认识
    </a></div>
      <div class="post-nav-item">
    <a href="/%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%80%9A%E4%BF%A1%E4%B9%8BKafka%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%BA%94%E7%94%A8/" rel="next" title="分布式消息通信之Kafka的基本应用">
      分布式消息通信之Kafka的基本应用 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%80%9A%E4%BF%A1%E4%B9%8BKafka-%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">分布式消息通信之Kafka 的实现原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88"><span class="nav-number">1.1.</span> <span class="nav-text">消息中间件能做什么?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Java-%E4%B8%AD%E4%BD%BF%E7%94%A8Kafka-%E8%BF%9B%E8%A1%8C%E9%80%9A%E4%BF%A1"><span class="nav-number">1.2.</span> <span class="nav-text">Java 中使用Kafka 进行通信.</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BE%9D%E8%B5%96"><span class="nav-number">1.2.1.</span> <span class="nav-text">依赖</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E7%AB%AF%E4%BB%A3%E7%A0%81"><span class="nav-number">1.2.2.</span> <span class="nav-text">发送端代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E7%AB%AF%E4%BB%A3%E7%A0%81"><span class="nav-number">1.2.3.</span> <span class="nav-text">消费端代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="nav-number">1.2.4.</span> <span class="nav-text">异步发送</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#batch-size"><span class="nav-number">1.2.5.</span> <span class="nav-text">batch.size</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#linger-ms"><span class="nav-number">1.2.6.</span> <span class="nav-text">linger.ms</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%E5%88%86%E6%9E%90"><span class="nav-number">1.3.</span> <span class="nav-text">一些基础配置分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#group-id"><span class="nav-number">1.3.1.</span> <span class="nav-text">group.id</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#enable-auto-commit"><span class="nav-number">1.3.2.</span> <span class="nav-text">enable.auto.commit</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#auto-offset-reset"><span class="nav-number">1.3.3.</span> <span class="nav-text">auto.offset.reset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#max-poll-records"><span class="nav-number">1.3.4.</span> <span class="nav-text">max.poll.records</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spring-%E6%95%B4%E5%90%88Kafka"><span class="nav-number">1.4.</span> <span class="nav-text">Spring 整合Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Jar-%E4%BE%9D%E8%B5%96"><span class="nav-number">1.4.1.</span> <span class="nav-text">Jar 依赖</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">1.4.2.</span> <span class="nav-text">生产者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">1.4.3.</span> <span class="nav-text">消费者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">1.4.4.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95"><span class="nav-number">1.4.5.</span> <span class="nav-text">测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90"><span class="nav-number">1.5.</span> <span class="nav-text">原理分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B3%E4%BA%8ETopic%E5%92%8CPartition"><span class="nav-number">1.5.1.</span> <span class="nav-text">关于Topic和Partition</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Topic"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">Topic</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Partition"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">Partition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Topic%E5%92%8CPartition-%E7%9A%84%E5%AD%98%E5%82%A8"><span class="nav-number">1.5.1.3.</span> <span class="nav-text">Topic和Partition 的存储</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91"><span class="nav-number">1.6.</span> <span class="nav-text">关于消息分发</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91%E7%AD%96%E7%95%A5"><span class="nav-number">1.6.1.</span> <span class="nav-text">Kafka 消息分发策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="nav-number">1.6.2.</span> <span class="nav-text">代码演示</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89partition"><span class="nav-number">1.6.2.1.</span> <span class="nav-text">自定义partition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E7%AB%AF%E4%BB%A3%E7%A0%81%E6%B7%BB%E5%8A%A0%E5%88%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA"><span class="nav-number">1.6.2.2.</span> <span class="nav-text">发送端代码添加到自定义分区</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E7%9A%84%E9%BB%98%E8%AE%A4%E5%88%86%E5%8F%91%E6%9C%BA%E5%88%B6"><span class="nav-number">1.6.3.</span> <span class="nav-text">消息的默认分发机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E7%AB%AF%E5%A6%82%E4%BD%95%E6%B6%88%E8%B4%B9%E6%8C%87%E5%AE%9A%E7%9A%84%E5%88%86%E5%8C%BA"><span class="nav-number">1.6.4.</span> <span class="nav-text">消费端如何消费指定的分区</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E5%8E%9F%E7%90%86"><span class="nav-number">1.7.</span> <span class="nav-text">消息的消费原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E5%8E%9F%E7%90%86%E6%BC%94%E7%A4%BA"><span class="nav-number">1.7.1.</span> <span class="nav-text">Kafka消息消费原理演示</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA-3%E4%B8%AApartition-%E5%AF%B9%E5%BA%943%E4%B8%AAconsumer"><span class="nav-number">1.7.1.1.</span> <span class="nav-text">代码演示(3个partition 对应3个consumer)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA-3%E4%B8%AApartition-%E5%AF%B9%E5%BA%942%E4%B8%AAconsumer"><span class="nav-number">1.7.1.2.</span> <span class="nav-text">代码演示(3个partition 对应2个consumer)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA-3%E4%B8%AApartition-%E5%AF%B9%E5%BA%944%E4%B8%AA%E6%88%96%E8%80%854%E4%B8%AA%E4%BB%A5%E4%B8%8A%E7%9A%84consumer"><span class="nav-number">1.7.1.3.</span> <span class="nav-text">代码演示(3个partition  对应4个或者4个以上的consumer)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#consumer%E5%92%8Cpartition%E7%9A%84%E6%95%B0%E9%87%8F%E5%BB%BA%E8%AE%AE"><span class="nav-number">1.7.2.</span> <span class="nav-text">consumer和partition的数量建议</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%9D%E8%80%83-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E8%A7%A6%E5%8F%91%E8%BF%99%E4%B8%AA%E7%AD%96%E7%95%A5%E5%91%A2"><span class="nav-number">1.7.3.</span> <span class="nav-text">思考: 什么时候会触发这个策略呢?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-number">1.7.4.</span> <span class="nav-text">什么是分区分配策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RangeAssignor%EF%BC%88%E8%8C%83%E5%9B%B4%E5%88%86%E5%8C%BA%EF%BC%89"><span class="nav-number">1.7.4.1.</span> <span class="nav-text">RangeAssignor（范围分区）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RoundRobinAssignor%EF%BC%88%E8%BD%AE%E8%AF%A2%E5%88%86%E5%8C%BA%EF%BC%89"><span class="nav-number">1.7.4.2.</span> <span class="nav-text">RoundRobinAssignor（轮询分区）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#StrickyAssignor-%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-number">1.7.4.3.</span> <span class="nav-text">StrickyAssignor 分配策略</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B0%81%E6%9D%A5%E6%89%A7%E8%A1%8C-rebalance-%E4%BB%A5%E5%8F%8A%E7%AE%A1%E7%90%86consumer-%E7%9A%84group-%E5%91%A2"><span class="nav-number">1.7.5.</span> <span class="nav-text">谁来执行 rebalance 以及管理consumer 的group 呢?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9Acoordinator"><span class="nav-number">1.7.6.</span> <span class="nav-text">如何确定coordinator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JoinGroup-%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="nav-number">1.7.7.</span> <span class="nav-text">JoinGroup 的过程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Join"><span class="nav-number">1.7.7.1.</span> <span class="nav-text">Join</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Synchronizing-Group-State%E9%98%B6%E6%AE%B5"><span class="nav-number">1.7.8.</span> <span class="nav-text">Synchronizing Group State阶段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.7.9.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E6%B6%88%E8%B4%B9%E7%AB%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E4%BD%8D%E7%BD%AE"><span class="nav-number">1.7.10.</span> <span class="nav-text">如何保存消费端的消费位置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFoffset"><span class="nav-number">1.7.10.1.</span> <span class="nav-text">什么是offset</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#offset-%E5%9C%A8%E5%93%AA%E9%87%8C%E7%BB%B4%E6%8A%A4"><span class="nav-number">1.7.10.2.</span> <span class="nav-text">offset 在哪里维护</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="luyanan"
      src="/images/logo.jpg">
  <p class="site-author-name" itemprop="name">luyanan</p>
  <div class="site-description" itemprop="description">程序员报社</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">227</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/luyanan0718" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;luyanan0718" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/luyanan0718@163.com" title="E-Mail → luyanan0718@163.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://luyanan.com/" title="https:&#x2F;&#x2F;luyanan.com">Site</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">luyanan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"live2d-widget-model-haru"},"display":{"position":"right","width":150,"height":300},"mobile":null});</script></body>
</html>
